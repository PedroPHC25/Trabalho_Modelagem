% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  twocolumn]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}
\usepackage{setspace}
\usepackage{multicol}
\usepackage[brazilian]{babel}
\setlength{\columnsep}{0.75cm}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\author{}
\date{\vspace{-2.5em}}

\begin{document}

\twocolumn[
\begin{@twocolumnfalse}

\begin{center}
{\LARGE \textbf{Sobredispersão em Modelos de Contagem}\\
Modelagem Estatística \par}
\vspace{0.5cm}

{\large Pedro Henrique Coterli \par}

{\large \today \par}
\end{center}

\vspace{1cm}
\end{@twocolumnfalse}
]

\section{Introdução}\label{introduuxe7uxe3o}

O presente trabalho tem como objetivo investigar a sobredispersão em
dados de contagem e seus efeitos no ajuste de modelos estatísticos, como
modelos lineares generalizados (GLMs). Serão considerados modelos de
regressão Poisson, Binomial Negativo e Poisson inflado de zeros,
aplicados a dados de turismo da região do Texas, nos Estados Unidos.
Busca-se avaliar como a sobredispersão afeta o desempenho desses
modelos, bem como discutir estratégias para reduzir seus impactos e
melhorar a qualidade dos ajustes.

\subsection{Os dados}\label{os-dados}

Os dados utilizados para este estudo foram retirados da biblioteca
Applied Econometrics with R (AER)\footnote{\url{https://rdrr.io/cran/AER/}}.
Será utilizada a base RecreationDemand\footnote{\url{https://rdrr.io/cran/AER/man/RecreationDemand.html}},
que contém dados sobre o número de viagens de barco recreativas ao Lago
Somerville, no Texas, em 1980, com base em uma pesquisa administrada a
2000 proprietários de barcos de lazer registrados em 23 condados do
leste do estado.

Estão presentes 659 observações com 8 variáveis, que estão descritas a
seguir:

\begin{itemize}
\tightlist
\item
  \textbf{trips}: assume valores naturais (incluindo 0) e representa o
  número de viagens de barco recreativas ao lago Somerville em 1980;
\item
  \textbf{quality}: assume valores de 1 a 5 e representa a classificação
  fornecida pelo indivíduo sobre a qualidade das instalações do lago;
\item
  \textbf{ski}: assume valores ``yes'' ou ``no'' e indica se o indivíduo
  praticava (ou se praticaria, caso nunca tivesse ido) esqui aquático no
  lago;
\item
  \textbf{income}: assume valores naturais e representa a renda familiar
  anual do entrevistado (em milhares de dólares);
\item
  \textbf{userfee}: assume valores ``yes'' ou ``no'' e indica se o
  indivíduo pagou uma taxa anual de uso do Lago Somerville;
\item
  \textbf{costC}: assume valores positivos e representa as despesas
  estimadas para visitar o Lago Conroe (em dólares);
\item
  \textbf{costS}: assume valores positivos e representa as despesas
  estimadas para visitar o Lago Somerville (em dólares);
\item
  \textbf{costH}: assume valores positivos e representa as despesas
  estimadas para visitar o Lago Houston (em dólares).
\end{itemize}

Uma limitação apresentada por esses dados diz respeito à variável
\textbf{quality}: apesar de possuir uma escala de 1 a 5, ela recebe o
valor 0 para indivíduos que não haviam visitado o lago Somerville, que,
como veremos mais adiante, compõem a maioria dos registros.

\section{Métodos}\label{muxe9todos}

\subsection{Os modelos}\label{os-modelos}

No presente trabalho, o objetivo no que se refere à modelagem será
regredir a variável de contagem \textbf{trips} sobre outras das
variáveis descritas anteriormente. A seleção dessas variáveis será
realizada por meio de uma análise exploratória de cada uma delas, em que
serão exploradas tanto suas distribuições univariadas quanto suas
relações com a variável resposta.

Serão considerados nesse estudo 3 modelos estatísticos, descritos a
seguir.

\subsubsection{Modelo Poisson}\label{modelo-poisson}

Frequentemente utilizada para modelar dados de contagem, a regressão
Poisson possui a seguinte forma:

\[
\begin{array}{c}
Y_i \sim \text{Poisson}(\theta_i) \\
\mathbb{E}[Y_i] = \mu_i = e^{{X_i}^T\beta}
\end{array}
\]

onde \(Y_i\) é a variável resposta (nesse caso, \textbf{trips}) e
\(X_i\) é o vetor das covariáveis de interesse, ambos indexados pelo
i-ésimo registro. Aqui, a função de ligação utilizada é a canônica para
a família Poisson: \(g(\mu_i) = \log({X_i}^T\beta)\).

Para o processo de estimação do vetor de parâmetros \(\beta\), será
utilizado o método de máxima verossimilhança (MV). Algumas das razões
para tal escolha são:

\begin{itemize}
\item
  Não há informação a priori para ser fornecida ao modelo. Assim, a
  distribuição a priori de \(\beta\) seria uma distribuição pouco
  informativa e sua posteriori seria praticamente a verossimilhança,
  sendo, portanto, equivalente ao método de MV.
\item
  A otimização numérica para a busca da estimativa de MV é matemática e
  computacionalmente mais simples que a necessária na abordagem
  Bayesiana. Enquanto a primeira utiliza de métodos simples como Fisher
  Scoring e Iteractive Weighted Least Squares (IWLS), a segunda
  necessita de algoritmos mais complexos como Markov Chain Monte Carlo
  (MCMC) e Variational Inference.
\item
  Dado que a base utilizada possui uma quantidade razoável de amostras
  (mais de 600), as estimativas de MV provavelmente apresentarão um bom
  desempenho, graças a sua normalidade assintótica.
\end{itemize}

Para a aproximação numérica da estimativa de máxima verossimilhança,
será utilizado o método de Fisher Scoring, que atualiza o vetor de
parâmetros da seguinte forma:

\[
\beta^{(t+1)} = \beta^{(t)} + [\mathbb{E}[-\nabla^2 l(\beta^{(t)})]]^{-1} \nabla l(\beta^{(t)})
\]

onde \(l(\beta)\) é a função de log-verossimilhança, \(\nabla l(\beta)\)
é o gradiente (score) e \(\nabla^2 l(\beta)\) é a Hessiana, todos
avaliados em \(\beta\). Esse método difere do Newton-Raphson clássico ao
substituir a matriz Hessiana pela sua esperança, que, com alguns ajustes
de sinais, torna-se a informação de Fisher. Algumas razões por essa
preferência são:

\begin{itemize}
\item
  Em GLMs, a informação de Fisher tem uma forma conhecida, podendo ser
  calculada como \(\mathbb{I}(\beta) = X^TWX\), onde \(X\) é a matriz de
  desenho (dos dados) e \(W\) é uma matriz diagonal com a i-ésima
  entrada sendo:

  \[
  w_i = \left(\dfrac{d\mu_i}{d\eta_i}\right)^2 \cdot \dfrac{1}{Var(Y_i)},
  \]

  com \(\eta_i = {X_i}^T\beta\). Graças a isso, esse algoritmo pode ser
  implementado como um simples Iterative Weighted Least Squares (IWLS),
  sendo resolvido de forma computacionalmente eficiente ao solucionar um
  problema de mínimos quadrados ponderados a cada iteração.
\item
  Se a função de ligação utilizada for a canônica, derivada da
  distribuição da família exponencial, então os métodos são
  equivalentes, coincidindo assintoticamente. No entanto, o Fisher
  Scoring geralmente funciona de forma mais robusta e é mais eficiente
  computacionalmente, como citado no item anterior.
\end{itemize}

\subsubsection{Modelo Binomial Negativo}\label{modelo-binomial-negativo}

Utilizado principalmente como um substituto do modelo Poisson, o modelo
Binomial Negativo possui a seguinte forma:

\[
\begin{array}{c}
Y_i \sim \text{NBin}(\mu_i, \phi) \\
\mathbb{E}[Y_i] = \mu_i = e^{{X_i}^T\beta}
\end{array}
\]

onde a função de massa de probabilidade dessa parametrização da
distribuição Binomial Negativa é a seguinte\footnote{\url{https://mc-stan.org/docs/functions-reference/unbounded_discrete_distributions.html\#nbalt}}:

\[
\text{NBin}(y | \mu, \phi) = \binom{y+\phi-1}{y} \left(\dfrac{\mu}{\mu+\phi}\right)^y \left(\dfrac{\phi}{\mu+\phi}\right)^\phi
\]

Esse modelo é adequado para ajustar dados de contagem, assim como o
Poisson. No entanto, ao contrário deste, ele fornece a possibilidade de
modelar separadamente os valores da média e da variância (fixos como
iguais no modelo Poisson). Com isso, ele possui a capacidade de
ajustar-se melhor a dados de contagem que apresentam sobredispersão.

Nessa parametrização, o parâmetro da média permanece com o mesmo
significado. Entretanto, agora há um parâmetro a mais: \(\phi\), que
modela o inverso da sobredispersão. Isso é possível pois a variância
passa a ser definida como:

\[
Var(Y) = \mu + \dfrac{\mu^2}{\phi}
\]

Com isso, quanto menor o valor de \(\phi\), maior é a variância dos
dados e mais distante da média ela está. Analogamente, quando
\(\phi \rightarrow \infty\), essa variância se aproxima da própria média
e o modelo volta a ser o de Poisson. Dessa forma, passa a ser possível
modelar dados de contagem de modo que a variância não seja idêntica à
média.

Mais uma vez, a função de ligação desse modelo é o logaritmo:
\(\log(\mu_i) = X_i^T\beta\), devido a ela ser a função de ligação
canônica dessa parametrização da distribuição Binomial Negativa na forma
da família exponencial. Sua utilização proporciona as vantagens
descritas na seção anterior com relação ao uso do método de Fisher
Scoring para a aproximação numérica da estimativa de MV.

Assim como com o modelo Poisson, será aplicado o método de máxima
verossimilhança para estimativa dos parâmetros, pelas mesmas
justificativas.

Além disso, será novamente aplicado o método de otimização por Fisher
Scoring para o cálculo da estimativa do vetor de parâmetros \(\beta\), e
a explicação para tal escolha é a mesma do modelo Poisson. A única
diferença é que, como agora há ``dois'' parâmetros a serem estimados (o
vetor \(\beta\) e o valor \(\phi\)), será adotada uma estratégia de
otimização em duas etapas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Com \(\phi\) fixo, \(\beta\) é encontrado por MV com Fisher Scoring.
\item
  Com \(\beta\) fixo, \(\phi\) é encontrado numericamente maximizando a
  verossimilhança atual.
\end{enumerate}

Esse processo é repetido até os parâmetros convergirem.

\subsubsection{Modelo Poisson inflado de
zeros}\label{modelo-poisson-inflado-de-zeros}

O modelo Poisson inflado de zeros (ZIP da sigla em inglês) é uma
adaptação do modelo Poisson para cenários com excesso de zeros na
variável resposta. É um modelo misto definido da seguinte
forma\footnote{\url{https://mc-stan.org/docs/stan-users-guide/finite-mixtures.html\#zero-inflation}}:

\[
\begin{aligned}
y_i = 0 \hspace{6em} &\text{ com probabilidade } \theta_i, \text{ e} \\
y_i \sim \text{Poisson}(\mu_i) \hspace{1.5em} &\text{  com probabilidade } 1-\theta_i
\end{aligned}
\]

onde \(\beta\) é estimado por um modelo Poisson para gerar
\(\mu_i = e^{Z_i^T\beta}\) e \(\gamma\) é estimado por um modelo
logístico para gerar \(\theta_i = \text{logit}^{-1}(W_i^T\gamma)\).
Aqui, \(Z_i\) e \(W_i\) são vetores com covariáveis do i-ésimo ponto de
dado, podendo conter variáveis diferentes ou comuns e até dimensões
diferentes.

Assim, para o i-ésimo ponto de dado, existe probabilidade \(\theta_i\)
de observar um 0 e probabilidade \(1-\theta_i\) de observar uma amostra
de uma distribuição \(\text{Poisson}(\mu_i)\). Com isso, esse modelo
permite separar zeros estruturais, ou seja, que não são explicados pelas
covariáveis explicativas da contagem, de zeros ocasionais, gerados pela
combinação de valores dessas covariáveis. Dessa forma, ele é capaz de
modelar todos esses zeros, que prejudicariam o desempenho de um modelo
Poisson convencional.

Sua função de verossimilhança pode ser escrita como a seguir:

\[
p(y_i | \theta_i, \mu_i) = 
\begin{cases}
\theta_i + (1-\theta_i) \cdot e^{-\mu_i}, & \text{se } y_i = 0 \\
(1-\theta_i) \cdot \dfrac{{\mu_i}^{y_i} e^{-\mu_i}}{y_i!}, & \text{se } y_i > 0
\end{cases}
\]

Para estimar os coeficientes \(\beta\) e \(\gamma\), será aplicada a
estratégia de máxima verossimilhança, utilizando as mesmas
justificativas dos modelos anteriores. Além disso, para realizar a
aproximação numérica, serão utilizados métodos numéricos que não serão
discutidos aqui, dada sua complexidade. O método de Fisher Scoring não
pode ser aplicado diretamente devido à estrutura mista do problema.

\subsection{Teste de sobredispersão sob modelo
Poisson}\label{teste-de-sobredispersuxe3o-sob-modelo-poisson}

Após o ajuste do modelo Poisson aos dados de interesse, será realizado
um teste estatístico para identificar a possibilidade de existência de
sobredispersão nos dados, ou seja, para verificar se sua variância
difere de sua média.

O teste utilizado foi descrito por Cameron \& Trivedi (1990) e baseia-se
na seguinte modelagem da variância da variável resposta:

\[
Var(Y_i) = \mu_i + \alpha \mu_i^2
\]

Assim, a hipótese nula diz que \(\alpha = 0\) e que, portanto, o modelo
de Poisson é adequado. Por outro lado, a hipótese alternativa afirma que
\(\alpha > 0\), tornando esse modelo inadequado.

Primeiramente, deve-se ajustar um modelo de Poisson aos dados. Em
seguida, é calculada a seguinte estatística de teste:

\[
Z_i = \dfrac{(Y_i - \hat{\mu_i})^2 - Y_i}{\hat{\mu_i}}
\]

onde \(\hat{\mu_i}\) é o valor estimado para a média da i-ésima
observação obtido pelo modelo de Poisson ajustado. Essa estatística mede
a diferença entre a variância observada e a variância esperada sob a
hipótese nula. Nota-se que, sob essa hipótese:

\[
\begin{aligned}
\mathbb{E}[Z_i] &= \dfrac{\mathbb{E}[(Y_i - \hat{\mu_i})^2] - \mathbb{E}[Y_i]}{\hat{\mu_i}} = \dfrac{Var(Y_i) - \hat{\mu_i}}{\hat{\mu_i}} = \\ &= \dfrac{\hat{\mu_i} - \hat{\mu_i}}{\hat{\mu_i}} = 0
\end{aligned}
\]

Com base nisso, a etapa final desse teste consiste em ajustar uma
regressão linear sem intercepto de \(Z\) sobre \(\hat{\mu}\), de forma
que \(\mathbb{E}[Z_i] = \beta \hat{\mu_i}\). Assim, caso o modelo
Poisson seja adequado, a expectativa é que \(\beta\) seja próximo de
\(0\). Em outras palavras, \(\beta\) aproxima o parâmetro \(\alpha\) da
parametrização da variância descrita acima. Portanto, caso \(\beta\)
seja estatisticamente significativo e positivo, há forte evidência da
presença de sobredispersão.

\subsection{Critérios de
avaliação}\label{crituxe9rios-de-avaliauxe7uxe3o}

A seguir, estão descritos os principais critérios utilizados para a
avaliação do desempenho dos modelos ajustados.

\subsubsection{Intervalo de confiança aproximado dos
parâmetros}\label{intervalo-de-confianuxe7a-aproximado-dos-paruxe2metros}

Para a avaliação da significância dos parâmetros do ajuste, será
utilizada a seguinte aproximação assintótica:

\[
z_j = \dfrac{\hat{\beta_j}}{se(\hat{\beta_j})} \approx \mathcal{N}(0, 1)
\]

onde
\(se(\hat{\beta_j}) \approx \sqrt{[\mathbb{I}(\hat{\beta})^{-1}]_{jj}}\).

Assim, é possível calcular um intervalo de confiança aproximado para
cada parâmetro e verificar se ele contém o valor 0. Caso não contenha, é
altamente provável que ele seja estatisticamente significativo.

\subsubsection{Resíduos de Pearson}\label{resuxedduos-de-pearson}

Os resíduos de Pearson são uma forma de quantificar a distância entre os
valores observados e os valores preditos por um modelo. O resíduo para o
i-ésimo ponto de dado é calculado da seguinte forma:

\[
r_i = \dfrac{y_i - \hat{\mu_i}}{\sqrt{Var(\hat{\mu_i})}}
\]

Dessa forma, quanto mais esses valores se aproximarem de 0, melhor é o
ajuste do modelo. Esses resíduos serão plotados em função do valor da
variável de resposta observada \(y_i\) (\textbf{trips}) para melhor
análise tanto interior ao modelo quanto entre modelos.

Uma possibilidade considerada para avaliação do ajuste foi a estatística
qui-quadrado de Pearson:

\[
X^2 = \sum r_i^2
\]

citada por Dobson (2018). De acordo com a autora, sob a hipótese de que
o modelo está correto, essa estatística teria aproximadamente a
distribuição \(\chi^2(N-p)\), onde \(N\) é o número de pontos de dados e
\(p\) é o número de parâmetros do modelo. No entanto, essa aproximação é
pobre se as frequências esperadas são muito pequenas, que é o caso desse
problema, como será mostrado mais adiante. Portanto, a utilização dessa
estatística não é viável.

\subsubsection{Estatística qui-quadrado de razão de
verossimilhança}\label{estatuxedstica-qui-quadrado-de-razuxe3o-de-verossimilhanuxe7a}

Seja \(l(\hat{\beta}; y)\) a log-verossimilhança do modelo de interesse
avaliada no estimador de máxima verossimilhança (EMV) e
\(l(\tilde{\beta}; y)\) a log-verossimilhança do modelo minimal (ou
seja, ajustado apenas com o intercepto) também avaliada em seu EMV.
Assim, a estatística qui-quadrado de razão de verossimilhança (C) pode
ser calculada como:

\[
C = 2[l(\hat{\beta}; y) - l(\tilde{\beta}; y)]
\]

Isso é equivalente a dizer que:

\[
C = D_{min} - D_{model}
\]

onde \(D_{min}\) e \(D_{model}\) são as deviances dos modelos minimal e
de interesse, respectivamente. Essas deviances são calculadas como:

\[
D_{\mathcal{M}} = 2[l(\dot{\beta}; y) - l(\hat{\beta}; y)]
\]

onde \(l(\dot{\beta}; y)\) é a log-verossimilhança do modelo saturado
(ou seja, com o número máximo de parâmetros que podem ser estimados)
avaliada em seu EMV.

Segundo Dobson (2018), a distribuição amostral aproximada para \(C\) é
\(\chi^2(p-1)\) sob a hipótese de que todos os \(p\) parâmetros, exceto
o termo do intercepto, são zero. Assim, \(C\) é uma estatística de teste
para a hipótese de que nenhuma das covariáveis é necessária para um
modelo parcimonioso. Dessa forma, se o valor de \(C\) for
estatisticamente significativo comparado com essa distribuição
qui-quadrado, então é altamente provável que as covariáveis utilizadas
sejam relevantes.

\subsubsection{AIC}\label{aic}

O Akaike Information Criterion (AIC) é uma medida utilizada para avaliar
e comparar modelos ajustados a um conjunto de dados. Ele pode ser
interpretado como uma estimativa do risco preditivo de um modelo, ou
seja, do erro esperado ao utilizá-lo para prever novos dados. Assim,
teoricamente, quanto menor seu valor, melhor o modelo.

Seu cálculo dá-se pela seguinte fórmula:

\[
\text{AIC} = 2p - 2l(\hat{\beta}; y)
\]

com os mesmos significados já definidos anteriormente.

\subsubsection{\texorpdfstring{Pseudo-\(\text{R}^2\)}{Pseudo-\textbackslash text\{R\}\^{}2}}\label{pseudo-textr2}

O pseudo-\(\text{R}^2\) é um análogo do \(\text{R}^2\) da regressão
linear múltipla para outros modelos, como regressão logística, Poisson e
Binomial Negativo. Ele é calculado da seguinte forma:

\[
\text{pseudo-R}^2 = \dfrac{l(\tilde{\beta}; y) - l(\hat{\beta}; y)}{l(\tilde{\beta}; y)}
\]

Segundo Dobson (2018), ele pode representar a melhora proporcional na
função de log-verossimilhança ocasionada pelos termos no modelo de
interesse, comparada ao modelo minimal. Assim, assume valores entre 0 e
1, com valores próximos de 0 indicando ajuste ruim e valores próximos de
1 indicando ótimo ajuste.

No entanto, vale destacar que essa estatística não é adequada para a
comparação de modelos de famílias diferentes, dado que as funções de
log-verossimilhança podem possuir escalas distintas. Assim, ela será
utilizada apenas para a avaliação interna de modelos.

\subsection{Ferramentas}\label{ferramentas}

Para a realização de todas as análises, ajustes de modelos e gerações de
visualizações, foi utilizado o software estatístico R. A biblioteca
\textbf{AER}\footnote{\url{https://rdrr.io/cran/AER/}} foi utilizada
para a obtenção dos dados, e a \textbf{ggplot2}\footnote{\url{https://ggplot2.tidyverse.org}}
e a \textbf{GGally}\footnote{\url{https://cran.r-project.org/web/packages/GGally/index.html}},
para a geração dos gráficos. Além disso, foi utilizado um método da
biblioteca \textbf{MASS}\footnote{\url{https://cran.r-project.org/web/packages/MASS/index.html}}
para o ajuste do modelo Binomial Negativo e um da biblioteca
\textbf{glmmTMB}\footnote{\url{https://cran.r-project.org/web/packages/glmmTMB/index.html}}
para o ajuste do modelo de inflação de zeros.

\section{Resultados}\label{resultados}

A seguir, serão exibidos e analisados os resultados obtidos a partir da
análise exploratória dos dados, seguidos dos ajustes e interpretações
dos modelos de interesse, além da aplicação do teste de sobredispersão
descrito na seção 2.2.

\subsection{Análise exploratória e seleção de
covariáveis}\label{anuxe1lise-exploratuxf3ria-e-seleuxe7uxe3o-de-covariuxe1veis}

Inicialmente, será apresentada uma análise a respeito da variável de
interesse a ser modelada, \textbf{trips}. Em seguida, as demais
covariáveis da base em estudo serão analisadas com o objetivo de
selecionar previamente variáveis potencialmente mais adequadas para o
ajuste dos modelos.

\subsubsection{\texorpdfstring{Variável resposta
\emph{trips}}{Variável resposta trips}}\label{variuxe1vel-resposta-trips}

Abaixo está a distribuição dessa variável:

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-2-1} \end{center}

É fácil notar a forte presença de dados com valor \(0\), indicando a
realização de nenhuma viagem recreativa de barco ao lago Somerville em
1980. Isso impacta diretamente nos valores da média e da variância
desses dados, como mostrado a seguir:

\begin{verbatim}
## Média:     2.24431
\end{verbatim}

\begin{verbatim}
## Variância: 39.59524
\end{verbatim}

A variância é consideravelmente maior que a média, o que é causado
justamente pelo excesso de zeros nessa variável, que reduz a média e
aumenta o efeito na variância dos valores não nulos. Assim, há um forte
indício de sobredispersão que possivelmente afetará o desempenho do
modelo Poisson, como será discutido nas próximas seções.

\subsubsection{\texorpdfstring{Covariável
\emph{quality}}{Covariável quality}}\label{covariuxe1vel-quality}

Abaixo está a distribuição dessa variável:

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-4-1} \end{center}

Mais uma vez, há um grande número de valores iguais a zero. No entanto,
a razão é diferente da fornecida para a variável \textbf{trips}: segundo
a documentação dos dados, esses valores correspondem a indivíduos que
não haviam visitado o lago e que, com isso, não avaliaram a qualidade de
suas instalações. Portanto, são equivalentes a valores desconhecidos.

A seguir, é apresentada a distribuição dos valores de \textbf{trips} em
função da covariável \textbf{quality}, sendo plotados todos os pontos
acima (com jitter para facilitar a visualização) e apenas as médias
dentro de cada valor de \textbf{quality} abaixo.

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-5-1} \end{center}

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-5-2} \end{center}

Aparentemente, existe uma correlação entre essa covariável e a variável
resposta, tornando-a potencialmente relevante para a modelagem.

Além disso, apesar do problema de dados ``desconhecidos'' citado
anteriormente, o uso dessa covariável mostra-se razoável, pois, como
visto no gráfico superior, a grande maioria dos registros com qualidade
\(0\) apresenta valor \(0\) também para \textbf{trips}. Isso é
semanticamente correto, dado que, como explicado na seção 1.2,
\textbf{quality} é \(0\) para registros de indivíduos que não viajaram
ao lago Somerville, ou seja, cujo \textbf{trips} é \(0\). Os dois
registros que divergem dessa interpretação podem ser dados incorretos,
perdidos ou cujos indivíduos apenas não avaliaram a qualidade das
instalações do lago.

Portanto, a covariável \textbf{quality} será incluída nos modelos que
serão ajustados.

\subsubsection{\texorpdfstring{Covariável
\emph{ski}}{Covariável ski}}\label{covariuxe1vel-ski}

A seguir está exibida a distribuição dessa variável:

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-6-1} \end{center}

Existe um relativo equilíbrio entre ambos os valores de \textbf{ski},
tornando-a adequada para o uso nos modelos em estudo.

Abaixo, está apresentada a distribuição da variável resposta em função
dessa covariável, tanto de forma bruta quanto agregada por meio da
média.

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-7-1} \end{center}

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-7-2} \end{center}

Analisando o gráfico inferior, é possível inferir que há uma certa
influência da prática de ski aquático na quantidade de viagens de barco
recreativas realizadas. Portanto, a covariável \textbf{ski} será
considerada para os ajustes dos modelos de interesse.

\subsubsection{\texorpdfstring{Covariável
\emph{income}}{Covariável income}}\label{covariuxe1vel-income}

Abaixo está apresentada a distribuição dessa variável:

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-8-1} \end{center}

A distribuição dos dados sobre essa variável não apresenta problemas
visíveis.

A seguir, está plotada a distribuição de \textbf{trips} em relação a
essa covariável, da mesma forma que com as anteriores.

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-9-1} \end{center}

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-9-2} \end{center}

Parece existir uma relação entre essa covariável e a variável resposta
\textbf{trips}, com valores maiores de renda implicando números menores
de viagens. Dessa forma, a covariável \textbf{income} também será
incluída nos ajustes dos modelos considerados.

\subsubsection{\texorpdfstring{Covariável
\emph{userfee}}{Covariável userfee}}\label{covariuxe1vel-userfee}

Visualizando a distribuição dessa covariável, obtém-se:

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-10-1} \end{center}

Nota-se um forte desbalanceamento nos valores dessa variável binária, o
que pode afetar o desempenho dos modelos. Isso pode ocorrer devido à
dificuldade de estimar precisamente o parâmetro referente à categoria
mais rara (``yes'') e à possibilidade de o modelo não detectar o efeito
dessa covariável por causa da pequena quantidade de registros em uma das
categorias.

Ainda assim, será verificada a relação entre essa covariável e
\textbf{trips}. Abaixo está o resultado:

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-11-1} \end{center}

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-11-2} \end{center}

Como visto, a covariável \textbf{userfee} parece influenciar de forma
considerável o valor da variável resposta. No entanto, devido ao
problema de desequilíbrio mostrado anteriormente, os dados da categoria
rara podem introduzir ruído excessivo, não sendo adequados para o ajuste
de modelos. Portanto, essa covariável não será considerada.

\subsubsection{\texorpdfstring{Covariáveis \emph{costC}, \emph{costS} e
\emph{costH}}{Covariáveis costC, costS e costH}}\label{covariuxe1veis-costc-costs-e-costh}

Por último, serão analisadas conjuntamente as 3 variáveis de despesas
estimadas. A seguir, estão as distribuições dessas covariáveis.

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-12-1} \end{center}

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-12-2} \end{center}

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-12-3} \end{center}

Suas distribuições são bem similares, o que sugere uma relação de
colinearidade entre elas. Para investigar isso, será verificada a
correlação entre essas três variáveis aos pares:

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-13-1} \end{center}

É evidente a colinearidade entre essas variáveis. Assim, para manter o
princípio da independência das covariáveis e evitar problemas como falta
de identificabilidade, será utilizada apenas uma delas na modelagem.
Para realizar essa escolha, serão analisadas as correlações entre cada
uma dessas variáveis e a variável resposta \textbf{trips}. Abaixo estão
os resultados:

\begin{verbatim}
## -> Correlação com trips:
\end{verbatim}

\begin{verbatim}
## costC: -0.04221274
\end{verbatim}

\begin{verbatim}
## costS: -0.1237036
\end{verbatim}

\begin{verbatim}
## costH: -0.02051193
\end{verbatim}

Dessa forma, conclui-se que, do ponto de vista de correlação, a variável
\textbf{costS} é a mais apropriada. Além disso, sob uma perspectiva
semântica, essa mesma variável também seria a mais adequada, dado que a
variável \textbf{trips} corresponde ao número de viagens ao lago
Somerville, e \textbf{costS} representa o custo estimado de uma viagem a
esse mesmo lago, melhorando a interpretação do modelo.

Portanto, as variáveis \textbf{costC} e \textbf{costH} serão
descartadas, mantendo-se apenas \textbf{costS}.

\subsubsection{Resumo}\label{resumo}

Finalmente, com base em todas as análises realizadas previamente, as
variáveis que serão utilizadas no ajuste dos modelos são:

\begin{itemize}
\tightlist
\item
  \textbf{quality}
\item
  \textbf{ski}
\item
  \textbf{income}
\item
  \textbf{costS}
\end{itemize}

\subsection{Ajuste do modelo Poisson}\label{ajuste-do-modelo-poisson}

A seguir, será realizado o ajuste do modelo Poisson, como definido na
seção 2.1.1, aos dados de interesse, modelando a variável resposta
\textbf{trips} em função das covariáveis listadas na seção anterior.

Vale ressaltar que a covariável \textbf{costS} foi transformada por meio
de uma divisão por 100. Isso mostrou-se adequado após alguns testes que
mostraram que seu coeficiente possuia magnitude inferior à dos demais, o
que é causado pelo fato de sua unidade ser \emph{dólares}, enquanto
\textbf{income}, por exemplo, é medida em \emph{milhares de dólares}.
Assim, com sua nova unidade de medida sendo \emph{centenas de dólares},
seu coeficiente torna-se mais comparável e mais interpretável.

Além disso, tanto a covariável \textbf{income} quanto a versão
transformada de \textbf{costS} foram centradas para facilitar sua
interpretação.

Abaixo está o resultado do ajuste segundo \texttt{glm()} do R:

\begin{verbatim}
## Resultados do GLM Poisson (AIC = 3599)
\end{verbatim}

\begin{verbatim}
## Deviances: nulo ------ 4849.69
\end{verbatim}

\begin{verbatim}
##            residual -- 2835.88
\end{verbatim}

\begin{verbatim}
## Coef.         Est.     SE      p-valor
\end{verbatim}

\begin{verbatim}
## --------------------------------------
\end{verbatim}

\begin{verbatim}
## (Intercept)   -0.974   0.068   <2e-16
## quality        0.559   0.016   <2e-16
## skiyes         0.537   0.056   <2e-16
## income_c      -0.168   0.019   <2e-16
## costS_100_c   -1.667   0.103   <2e-16
\end{verbatim}

Como pode ser observado por meio dos intervalos de confiança de cada
parâmetro e de seus respectivos p-valores, todos eles se mostraram
estatisticamente significativos sob esse modelo.

\subsubsection{Avaliação do modelo}\label{avaliauxe7uxe3o-do-modelo}

A seguir, serão aplicadas algumas das estatísticas e testes descritos na
seção 2.3 para avaliar esse modelo.

\textbf{Resíduos de Pearson}

Primeiramente, será avaliada a distribuição dos resíduos de Pearson em
função dos valores preditos para a variável resposta:

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-16-1} \end{center}

Ao analisar o gráfico, é possível notar que a maioria dos resíduos
consideráveis, ou seja, com valores absolutos maiores, é positiva. Isso
indica que, para diversos registros, o modelo subestimou o valor de
\textbf{trips}, isto é, o valor verdadeiro era muito maior que o
previsto. Esse resultado demonstra que o modelo de Poisson não está
conseguindo modelar adequadamente a alta variância dos dados, não sendo
capaz de prever corretamente valores mais extremos.

\textbf{Estatística qui-quadrado de razão de verossimilhança}

A seguir, será calculada a estatística qui-quadrado de razão de
verossimilhança (C) para esse modelo.

\begin{verbatim}
## Estatística C: 2013.809
\end{verbatim}

\begin{verbatim}
## Graus de liberdade: 4
\end{verbatim}

\begin{verbatim}
## p-valor: 0
\end{verbatim}

O valor de \(C\) é altamente significativo quando comparado à
distribuição qui-quadrado de \(4\) graus de liberdade, tanto que seu
p-valor é praticamente nulo. Assim, isso sugere que os parâmetros do
modelo não são nulos e que, portanto, suas covariáveis associadas são
relevantes para a modelagem de \textbf{trips}.

\textbf{Pseudo-\(\text{R}^2\)}

Agora, será calculado o valor do pseudo-\(\text{R}^2\) desse modelo:

\begin{verbatim}
## Pseudo-R2: 0.3594313
\end{verbatim}

Com base nessa estatística, é possível inferir que o modelo de Poisson
ajustado obteve uma melhoria de aproximadamente \(36\%\) em seu
desempenho quando comparado com o modelo minimal da mesma família, o que
indica um resultado razoável, mas que pode ser melhorado com o uso de
outros modelos, como será apresentado a seguir.

\subsection{Teste para
sobredispersão}\label{teste-para-sobredispersuxe3o}

Nesse momento, será realizado o teste de sobredispersão definido na
seção 2.2, aplicado sobre os dados de interesse. Após o ajuste da
estatística de teste às previsões, o resultado obtido foi o seguinte:

\begin{verbatim}
## Resultados da Sobredispersão
\end{verbatim}

\begin{verbatim}
## Coef.         Est.     SE      p-valor
\end{verbatim}

\begin{verbatim}
## --------------------------------------
\end{verbatim}

\begin{verbatim}
## pred          21.028   7.961   0.008
\end{verbatim}

Como é possível observar, o parâmetro do modelo possui considerável
significância estatística, o que sugere a existência de sobredispersão
nesses dados. Isso justifica o desempenho mediano do modelo Poisson
sobre eles. Na próxima seção, será ajustado um modelo Binomial Negativo
com o objetivo de tentar contornar esse problema.

\subsection{Ajuste do modelo Binomial
Negativo}\label{ajuste-do-modelo-binomial-negativo}

A seguir, será ajustado um modelo Binomial Negativo aos dados em estudo
conforme definido na seção 2.1.2 e com as mesmas covariáveis e
respectivas transformações utilizadas no modelo Poisson. Será utilizado
o método \texttt{glm.nb} da biblioteca \textbf{MASS} do R.

\begin{verbatim}
## Resultados do GLM NegBin (AIC = 1817.5)
\end{verbatim}

\begin{verbatim}
## Phi = 0.4460 (SE = 0.0418)
\end{verbatim}

\begin{verbatim}
## Deviances: nulo ------ 923.49
\end{verbatim}

\begin{verbatim}
##            residual -- 455.70
\end{verbatim}

\begin{verbatim}
## Coef.         Est.     SE      p-valor
\end{verbatim}

\begin{verbatim}
## --------------------------------------
\end{verbatim}

\begin{verbatim}
## (Intercept)   -1.829   0.147   <2e-16
## quality        0.913   0.043   <2e-16
## skiyes         0.558   0.170    0.001
## income_c      -0.066   0.048    0.173
## costS_100_c   -1.295   0.247    0.000
\end{verbatim}

Ao contrário do modelo de Poisson, nesse modelo, nem todos os
coeficientes se mostraram significativos: o coeficiente da covariável
\textbf{income} perdeu sua significância. Uma possível razão para isso é
a inclusão do parâmetro de sobredispersão \(\phi\), que absorveu a
variância que o modelo Poisson estava tentando ajustar por meio da
covariável \textbf{income}. Dessa forma, será ajustado um novo modelo
sem essa covariável de forma a respeitar o princípio da parcimônia.

\vspace{3cm}

\begin{verbatim}
## Resultados do GLM NegBin (AIC = 1817.1)
\end{verbatim}

\begin{verbatim}
## Phi = 0.4399 (SE = 0.0410)
\end{verbatim}

\begin{verbatim}
## Deviances: nulo ------ 915.43
\end{verbatim}

\begin{verbatim}
##            residual -- 453.57
\end{verbatim}

\begin{verbatim}
## Coef.         Est.     SE      p-valor
\end{verbatim}

\begin{verbatim}
## --------------------------------------
\end{verbatim}

\begin{verbatim}
## (Intercept)   -1.830   0.147   <2e-16
## quality        0.920   0.043   <2e-16
## skiyes         0.526   0.165    0.001
## costS_100_c   -1.405   0.249    0.000
\end{verbatim}

Os coeficientes estimados para as três covariáveis restantes apresentam
significância estatística.

A seguir, serão realizadas as avaliações desse ajuste semelhantemente a
como foi feito com o modelo Poisson. Comparações entre os resultados dos
modelos serão efetuadas após o ajuste dos 3 modelos em estudo.

\subsubsection{Avaliação do modelo}\label{avaliauxe7uxe3o-do-modelo-1}

\textbf{Resíduos de Pearson}

A primeira análise realizada será sobre a distribuição dos resíduos de
Pearson:

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-22-1} \end{center}

É notável a concentração dos resíduos em valores próximos de zero, o que
sugere um bom ajuste. Além disso, nota-se que os poucos resíduos com
maior magnitude são positivos, indicando que o modelo ainda subestima
alguns pontos de dados, ou seja, o valor verdadeiro da variável resposta
é bem maior que o previsto. Isso mostra que, apesar de modelar a
variância dos dados mais eficientemente que o modelo Poisson, o modelo
Binomial Negativo ainda comete alguns erros semelhantes aos cometidos
por esse último.

\vspace{2cm}

\textbf{Estatística qui-quadrado de razão de verossimilhança}

Abaixo, estão os resultados do teste sobre a estatística \(C\).

\begin{verbatim}
## Estatística C: 461.859
\end{verbatim}

\begin{verbatim}
## Graus de liberdade: 3
\end{verbatim}

\begin{verbatim}
## p-valor: 8.784565e-100
\end{verbatim}

Novamente, o valor da estatística \(C\) mostra-se altamente
significativo quando comparado com a distribuição \(\chi^2(3)\).
Portanto, há fortes indícios de que os parâmetros referentes às
covariáveis utilizadas são estatisticamente significativos, o que
representa uma melhoria no desempenho gerada pelo uso dessas
covariáveis.

\textbf{Pseudo-\(\text{R}^2\)}

Por fim, abaixo está o valor calculado para o pseudo-\(\text{R}^2\)
desse modelo:

\begin{verbatim}
## Pseudo-R2: 0.1513699
\end{verbatim}

Dessa forma, segundo essa estatística, o modelo Binomial Negativo
ajustado gerou uma melhoria de aproximadamente \(15\%\) no desempenho
quando comparado com o modelo minimal da mesma família. Isso parece
fraco, mas pode ser causado pelo fato de a verossimilhança do modelo
nulo já ser considerável, o que diminui a relevância de ajustes
melhores.

Além disso, esse valor é menor que o obtido pelo modelo Poisson, mas,
como explicado na seção 2.3.5, esses valores não são comparáveis por
virem de modelos de famílias diferentes.

\subsection{Ajuste do modelo Poisson inflado de
zeros}\label{ajuste-do-modelo-poisson-inflado-de-zeros}

Para o ajuste do modelo Poisson inflado de zeros, foram escolhidas, com
base em testes preliminares, a covariável \textbf{quality} para a
modelagem da etapa logística e as demais para a modelagem da etapa de
contagem. Assim, feito o ajuste, o resultado obtido foi o seguinte:

\begin{verbatim}
## Resultados do Modelo ZIP (AIC = 2631.8)
\end{verbatim}

\begin{verbatim}
## Modelo Condicional: 
## Coef.         Est.     SE      p-valor
## --------------------------------------
## (Intercept)    1.385   0.046   <2e-16
## skiyes         0.528   0.058   <2e-16
## income_c      -0.127   0.020    0.000
## costS_100_c   -1.504   0.103   <2e-16
\end{verbatim}

\begin{verbatim}
## Modelo de Inflação Zero: 
## Coef.         Est.     SE      p-valor
## --------------------------------------
## (Intercept)    2.973   0.228   <2e-16
## quality       -1.618   0.121   <2e-16
\end{verbatim}

Dada a seleção de covariáveis realizada, todos os coeficientes
mostraram-se estatisticamente significativos.

A seguir, esse modelo será avaliado segundo as mesmas métricas aplicadas
sobre os modelos anteriores.

\subsubsection{Avaliação do ajuste}\label{avaliauxe7uxe3o-do-ajuste}

\textbf{Resíduos de Pearson}

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-26-1} \end{center}

Nota-se uma concentração dos resíduos mais proeminentes em valores
positivos, indicando que, assim como o modelo Poisson, o modelo ZIP não
foi tão eficiente ao absorver a variância gerada pela sobredispersão.
Isso é perfeitamente válido, já que, apesar de ser um modelo mais
elaborado, a base de sua modelagem de contagem ainda é uma distribuição
Poisson convencional, que considera a média e a variância como iguais.
Na próxima seção, será verificado se ele conseguiu mitigar o problema do
excesso de zeros.

\textbf{Estatística qui-quadrado de razão de verossimilhança}

Aqui, será considerado como modelo nulo a versão do modelo ZIP sem o uso
de covariáveis, ou seja, ainda será mantida sua estrutura mista, mas
tanto a etapa Binomial quanto a etapa Poisson serão regredidas apenas
sobre interceptos.

\begin{verbatim}
## Estatística C: 2500.429
\end{verbatim}

\begin{verbatim}
## Graus de liberdade: 4
\end{verbatim}

\begin{verbatim}
## p-valor: 0
\end{verbatim}

Novamente, conclui-se que os coeficientes referentes às covariáveis
utilizadas provavelmente são estatisticamente significativos.

\textbf{Pseudo-\(\text{R}^2\)}

Por fim, a seguir está o valor calculado para o pseudo-\(\text{R}^2\)
desse modelo:

\begin{verbatim}
## Pseudo-R2: 0.252546
\end{verbatim}

Portanto, esse modelo apresenta uma melhoria de aproximadamente \(25\%\)
na verossimilhança em comparação com o modelo minimal, ajustado sem o
uso de covariáveis explicativas. Assim, ele apresenta uma performance
considerável, embora ainda permita a exploração de modelos mais
elaborados ou a inserção de covariáveis adicionais.

\subsection{Comparação dos modelos}\label{comparauxe7uxe3o-dos-modelos}

Finalmente, nesta seção, será efetuada a comparação dos desempenhos dos
três modelos ajustados, analisando-se, para esse fim, seus coeficientes
estimados, as distribuições de seus resíduos de Pearson, suas
estatísticas AIC (definido e justificado na seção 2.3.4) e seus
resultados na modelagem dos valores zero.

\subsubsection{Coeficientes estimados}\label{coeficientes-estimados}

A seguir, apresenta-se uma tabela com os valores estimados por cada
modelo para os coeficientes de cada covariável utilizada. Vale lembrar
que a interpretação desses parâmetros varia entre os modelos,
principalmente no caso do modelo misto ZIP.

\begin{center}
\footnotesize
\begin{tabular}{lrrrr}
  \hline
Termo & Poisson & NegBin & ZIP.Pois & ZIP.Bin \\ 
  \hline
(Intercept) & -0.97 & -1.83 & 1.38 & 2.97 \\ 
  quality & 0.56 & 0.92 &  & -1.62 \\ 
  skiyes & 0.54 & 0.53 & 0.53 &  \\ 
  income\_c & -0.17 &  & -0.13 &  \\ 
  costS\_100\_c & -1.67 & -1.40 & -1.50 &  \\ 
   \hline
\end{tabular}\end{center}
\normalsize

Em resumo, todos os modelos apontam direções semelhantes nos efeitos das
covariáveis utilizadas sobre a variável resposta \textbf{trips}, o que
pode ser observado pelos sinais dos coeficientes estimados em cada
modelo. Os únicos casos que não obedecem a esse padrão são os
interceptos e o coeficiente de \textbf{quality}. Com relação a esse
último, enquanto os modelos de Poisson e Binomial Negativo apresentam
valores positivos para esse parâmetro, a etapa Binomial do modelo ZIP
atribui a ele um valor negativo. Embora pareça contraintuitivo, esse
resultado é coerente, já que, nesse modelo ZIP, quanto maior o valor de
\textbf{quality}, menor a probabilidade de a variável resposta ser
zerada e, com isso, maior seu valor potencial, indicando uma relação
positiva entre essas variáveis, consistente com os demais modelos.
Portanto, eles estão de acordo com respeito às direções dessas
correlações.

\subsubsection{Resíduos de Pearson}\label{resuxedduos-de-pearson-1}

A seguir, estão dispostos em conjunto os gráficos das distribuições dos
resíduos de Pearson de cada modelo para que seja realizada uma
comparação entre seus desempenhos.

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-30-1} \end{center}

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-30-2} \end{center}

\begin{center}\includegraphics{TrabalhoME_files/figure-latex/unnamed-chunk-30-3} \end{center}

Como pode ser observado, tanto o modelo Poisson quando o ZIP (que também
utiliza a distribuição Poisson) estimam valores muito menores que o
modelo Binomial Negativo, o que é explicado pela falta de modelagem do
fator de sobredispersão por parte desses modelos. Essa subestimação
também é confirmada pela grande quantidade de resíduos altamente
positivos em ambos os ajustes, que sugere sua falta de capacidade para
modelar valores extremos.

Por outro lado, o modelo Binomial Negativo apresenta uma distribuição
mais simétrica e próxima do zero, indicando um ajuste mais apropriado
aos dados. Isso pode ser justificado pela inclusão de um parâmetro de
sobredispersão, que permite a ele absorver de forma mais eficiente a
variância gerada pelos registros extremos.

\subsubsection{AIC}\label{aic-1}

Em seguida, serão comparadas as estatísticas AIC dos três modelos em
estudo.

\begin{center}
\begin{tabular}{lr}
  \hline
Modelo & AIC \\ 
  \hline
Poisson & 3598.95 \\ 
  NegBin & 1817.11 \\ 
  ZIP & 2631.78 \\ 
   \hline
\end{tabular}
\end{center}

Notavelmente, o modelo Binomial Negativo obteve um desempenho superior
ao dos modelos baseados na distribuição Poisson, devido à incorporação
do coeficiente de sobredispersão, que permite a ele separar a média da
variância e, assim, modelar de maneira mais adequada os valores
extremos.

Enquanto isso, o modelo ZIP apresenta um risco estimado menor que o
Poisson tradicional, o que se justifica pela sua capacidade de modelar
os zeros estruturais da variável resposta (o que será demonstrado a
seguir). Entretanto, ainda não apresenta um ajuste tão apropriado quanto
o do modelo Binomial Negativo devido à falta da modelagem da
sobredispersão, presente nesse último.

\subsubsection{Desempenho na modelagem dos valores
zero}\label{desempenho-na-modelagem-dos-valores-zero}

Por fim, será avaliado como cada um desses modelos desempenha com
relação à modelagem e previsão dos valores zero da variável resposta
\textbf{trips}. Para isso, em cada modelo:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Será feito seu ajuste.
\item
  Serão geradas amostras de previsões para os dados a partir da
  distribuição assumida por cada modelo com os parâmetros estimados.
\item
  Serão contabilizados os valores zero previstos.
\end{enumerate}

Esse processo será realizado 1000 vezes e a média dos resultados será
considerada para garantir uma estimativa estável dessa quantidade. Os
resultados estão exibidos a seguir:

\begin{center}
\begin{tabular}{lr}
  \hline
Modelo & MediaZeros \\ 
  \hline
REAL & 417.00 \\ 
  Poisson & 261.22 \\ 
  NegBin & 423.51 \\ 
  ZIP & 437.54 \\ 
   \hline
\end{tabular}
\end{center}

Analisando a tabela, é possível concluir que, de fato, o modelo Poisson
não estava ajustando de forma adequada o excesso de zeros dos dados da
variável \textbf{trips}, prevendo muito menos valores zero que a
quantidade verdadeira. Por outro lado, tanto o modelo Binomial Negativo
quanto o modelo ZIP apresentaram desempenho aceitável nesse quesito.
Nota-se, então, que a maior elaboração do modelo Poisson ao construir um
modelo misto, o ZIP, foi capaz de corrigir a deficiência do modelo
clássico com relação à modelagem desses valores. Enquanto isso, a
própria inclusão de um coeficiente de sobredispersão já foi suficiente
para o modelo Binomial Negativo obter uma boa capacidade de representar
os zeros observados.

\section{Discussão e Conclusão}\label{discussuxe3o-e-conclusuxe3o}

Portanto, com base nos experimentos e análises conduzidos, pode-se
concluir que a presença de sobredispersão na variável resposta a ser
modelada pode comprometer significativamente o desempenho de modelos
estatísticos quando não levada em consideração. Isso é exemplificado
pela aplicação de um modelo Poisson aos dados em estudo, o que gerou
resultados insatisfatórios na modelagem tanto de valores extremos quanto
de valores zero excessivos.

Ao refinar essa estratégia por meio da adoção de um modelo Poisson
inflado de zeros (ZIP), o desempenho relacionado ao excesso de zeros
obteve uma melhora significativa, com o modelo sendo capaz de absorver e
modelar os zeros estruturais presentes na base. Entretanto, ele ainda
apresentou desempenho insatisfatório na modelagem de valores extremos,
resultantes da alta variância dos dados.

Por fim, a inclusão de um coeficiente de sobredispersão por meio da
utilização de um modelo Binomial Negativo permitiu que as consequências
geradas pela alta variância fossem mitigadas, como mostrado pelos
resíduos relativamente pequenos quando comparados aos resíduos dos
modelos Poisson e ZIP. Ao mesmo tempo, essa nova característica também
forneceu ao modelo a capacidade de modelar os zeros estruturais,
proporcionando um desempenho geral superior aos demais modelos, sendo,
portanto, preferível dentre os modelos analisados.

No entanto, apesar dos desempenhos variados, todos os modelos estudados
apresentaram resultados medianos, não sendo capazes de alcançar um
ajuste plenamente satisfatório. Uma possível causa para isso é a falta
de dados mais relevantes, dado que o estudo foi limitado aos dados
presentes na base da biblioteca AER. Com isso, é provável que a
incorporação de novas covariáveis resultasse em modelos melhor
ajustados.

Além disso, com o objetivo de obter modelos mais adequados a esses
dados, esse trabalho poderia ser expandido por meio da aplicação e da
experimentação de novos modelos estatísticos, sejam variantes dos
apresentados aqui ou baseados em abordagens distintas. Uma possibilidade
seria o modelo Binomial Negativo inflado de zeros (ZINB da sigla em
inglês), que agrega a capacidade de absorção da sobredispersão do modelo
Binomial Negativo com a boa modelagem dos zeros estruturais fornecida
pelo modelo ZIP. Esse e outros modelos poderiam gerar resultados mais
robustos que os obtidos pelos estudados nesse projeto.

\section{Referências}\label{referuxeancias}

{[}Cameron \& Trivedi (1990){]} Cameron, A. C., \& Trivedi, P. K.
(1990). Regression-based tests for overdispersion in the Poisson model.
\emph{Journal of Econometrics, 46}(3), 347--364.
\url{https://doi.org/10.1016/0304-4076(90)90014-K}

{[}Dobson (2018){]} Dobson, A. J., \& Barnett, A. G. (2018). \emph{An
introduction to generalized linear models} (4th ed.). CRC Press.
\url{https://doi.org/10.1201/9781315182780}

Gelman, A., Hill, J., \& Vehtari, A. (2020). \emph{Regression and other
stories}. Cambridge University Press.
\url{https://doi.org/10.1017/9781139161879}

Stan Development Team. (n.d.). \emph{Finite mixtures}. Stan User's
Guide.
\url{https://mc-stan.org/docs/stan-users-guide/finite-mixtures.html}

\end{document}
